{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'MNIST_Subset.h5'\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "    b_group_key = list(f.keys())[1]\n",
    "    # Get the data\n",
    "    data = list(f[a_group_key])\n",
    "    target = list(f[b_group_key])\n",
    "dat = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    l = []\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            l.append(data[i][j][k])\n",
    "    dat.append(np.asarray(l))\n",
    "dat = np.asarray(dat)\n",
    "target = np.asarray(target)\n",
    "f = []\n",
    "for i in range(len(target)):\n",
    "    if target[i] == 7:\n",
    "        f.append([[1, 0]])\n",
    "    else:\n",
    "        f.append([[0, 1]])\n",
    "target = np.asarray(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return 1/(1 + np.exp(-s))\n",
    "\n",
    "def softmax(A):\n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum()\n",
    "\n",
    "def sigmoid_derv(s):\n",
    "    return sigmoid(s) * (1 - sigmoid(s))\n",
    "\n",
    "def cross_entropy(pred, real):\n",
    "    n_samples = real.shape[0]\n",
    "    res = pred - real\n",
    "    return res/n_samples\n",
    "\n",
    "# def error(pred, real):\n",
    "#     n_samples = real.shape[0]\n",
    "#     logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=0)])\n",
    "#     loss = np.sum(logp)/n_samples\n",
    "#     return loss\n",
    "def error(pred, real):\n",
    "    n_samples = real.shape[0]\n",
    "    logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=1)])\n",
    "    loss = np.sum(logp)/n_samples\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralnet:\n",
    "    def __init__(self, x, y, x_valid, y_valid, layers, neurons):\n",
    "        self.input = x\n",
    "        self.output = y\n",
    "        self.count = 0 \n",
    "        self.loss = 0\n",
    "        self.xvalid = x_valid\n",
    "        self.yvalid = y_valid\n",
    "        self.we = []\n",
    "        self.bi = []\n",
    "        self.layers = layers+1\n",
    "        self.lr = 0.001       # user defined learning rate\n",
    "        ip_dim = x.shape[1] # input layer size \n",
    "        op_dim = 2 # output layer size 2\n",
    "        w = []\n",
    "        b = []\n",
    "        for i in range(len(neurons)+1):\n",
    "            if i==0:\n",
    "                w.append(np.random.randn(ip_dim, neurons[i])) # weights\n",
    "                b.append(np.zeros((1, neurons[i])))           # biases\n",
    "            elif i==len(neurons):  \n",
    "                w.append(np.random.randn(neurons[i-1], op_dim))\n",
    "                b.append(np.zeros((1, op_dim)))\n",
    "            else:    \n",
    "                w.append(np.random.randn(neurons[i-1], neurons[i]))\n",
    "                b.append(np.zeros((1, neurons[i])))\n",
    "        self.weights = w\n",
    "        self.biases = b\n",
    "\n",
    "    \n",
    "    def feedforward(self):\n",
    "        a = []\n",
    "        z = []\n",
    "        for i in range(self.layers):\n",
    "            if i == 0:\n",
    "                z.append(np.dot(self.x, self.weights[i]) + self.biases[i])\n",
    "                a.append(sigmoid(z[i]))\n",
    "            elif i == self.layers-1:\n",
    "                z.append(np.dot(a[i-1], self.weights[i]) + self.biases[i])\n",
    "                a.append(softmax(z[i]))\n",
    "            else:    \n",
    "                z.append(np.dot(a[i-1], self.weights[i]) + self.biases[i])\n",
    "                a.append(sigmoid(z[i]))\n",
    "        self.a = a\n",
    "        self.z = z\n",
    "                    \n",
    "    def backprop(self):\n",
    "        loss = error(self.a[-1], self.y)\n",
    "        self.loss += loss\n",
    "#         if (self.a[-1][0][0]>=self.a[-1][0][1] and self.y[0][0]==1) or (self.a[-1][0][1]>self.a[-1][0][0] and self.y[0][1]==1):\n",
    "#             self.count+=1\n",
    "        a_delta = []\n",
    "        z_delta = []\n",
    "        l = len(self.a)\n",
    "        \n",
    "        for i in range(l):\n",
    "            if i == 0:\n",
    "                a_delta.append(cross_entropy(self.a[l-i-1], self.y))\n",
    "            else:\n",
    "                z_delta.append(np.dot(a_delta[i-1], self.weights[l-i].T))\n",
    "                a_delta.append(z_delta[i-1] * sigmoid_derv(self.a[l-i-1]))\n",
    "        \n",
    "        for i in range(len(self.a) - 1, -1, -1):\n",
    "            if i == 0:\n",
    "                self.weights[i] -= self.lr * np.dot(np.reshape(self.x.T,(784,1)), a_delta[l-i-1]) \n",
    "                self.biases[i] -= self.lr * np.sum(a_delta[l-i-1], axis=0, keepdims=True)\n",
    "            else: \n",
    "                self.weights[i] -= self.lr * np.dot(self.a[i-1].T, a_delta[l-i-1]) \n",
    "                self.biases[i] -= self.lr * np.sum(a_delta[l-i-1], axis=0, keepdims=True)\n",
    "    \n",
    "    def train(self): \n",
    "        w = []\n",
    "        valid_ac = []\n",
    "        train_ac = []\n",
    "        valid_loss = []\n",
    "        train_loss = []\n",
    "        b = []\n",
    "        for j in range(10):\n",
    "            self.count = 0 \n",
    "            self.loss = 0\n",
    "            for k in range(len(self.xvalid)):\n",
    "                self.x = self.xvalid[k]\n",
    "                self.y = self.yvalid[k]\n",
    "                self.feedforward()\n",
    "                if (self.a[-1][0][0]>=self.a[-1][0][1] and self.y[0][0]==1) or (self.a[-1][0][1]>self.a[-1][0][0] and self.y[0][1]==1):\n",
    "                    self.count+=1\n",
    "                loss = error(self.a[-1], self.y)\n",
    "                self.loss += loss    \n",
    "            valid_ac.append(self.count/len(self.xvalid))  \n",
    "            valid_loss.append(self.loss/len(self.xvalid))\n",
    "            self.count = 0 \n",
    "            self.loss = 0\n",
    "            for i in range(len(self.input)):\n",
    "                self.x = self.input[i]\n",
    "                self.y = self.output[i]\n",
    "                self.feedforward()\n",
    "                if (self.a[-1][0][0]>=self.a[-1][0][1] and self.y[0][0]==1) or (self.a[-1][0][1]>self.a[-1][0][0] and self.y[0][1]==1):\n",
    "                    self.count+=1\n",
    "                loss = error(self.a[-1], self.y)\n",
    "                self.loss += loss\n",
    "            print('accuracy after epoch ', j ,\" \",self.count/len(self.input))\n",
    "            train_ac.append(self.count/len(self.input))\n",
    "            train_loss.append(self.loss/len(self.input))\n",
    "            for i in range(len(self.input)):\n",
    "                self.x = self.input[i]\n",
    "                self.y = self.output[i]\n",
    "                self.feedforward()\n",
    "                self.backprop()    \n",
    "        return valid_ac,train_ac,valid_loss,train_loss\n",
    "        \n",
    "    def accuracy(self, x, y):\n",
    "        ac = []\n",
    "        acc = 0\n",
    "        for i in range(len(x)):\n",
    "            self.x = x[i]\n",
    "            self.y = y[i]\n",
    "            self.feedforward()\n",
    "            if (self.a[-1][0][0]>=self.a[-1][0][1] and self.y[0][0]==1) or (self.a[-1][0][1]>self.a[-1][0][0] and self.y[0][1]==1):\n",
    "                acc+=1\n",
    "        return acc\n",
    "    \n",
    "    def closs(self, x, y):\n",
    "        l=0\n",
    "        for i in range(len(x)):\n",
    "            self.x = x[i]\n",
    "            self.y = y[i]\n",
    "            self.feedforward()\n",
    "            loss = error(self.a[-1], self.y)\n",
    "            l += loss\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dat, target, test_size=0.10)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\siddha~1\\docume~1\\courses\\monsoo~1\\ml2019~1\\hw3\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy after epoch  0   0.4266581047610311\n",
      "accuracy after epoch  1   0.948078157967159\n",
      "accuracy after epoch  2   0.9573433629942207\n",
      "accuracy after epoch  3   0.9522979543161177\n",
      "accuracy after epoch  4   0.9643152004403266\n",
      "accuracy after epoch  5   0.9687184661957619\n",
      "accuracy after epoch  6   0.9690854050087148\n",
      "accuracy after epoch  7   0.9704614255572883\n",
      "accuracy after epoch  8   0.9702779561508118\n",
      "accuracy after epoch  9   0.9725713237317677\n"
     ]
    }
   ],
   "source": [
    "nn = neuralnet(x_train, y_train,x_valid,y_valid, 3, [100, 50, 50])\n",
    "[valid_ac,train_ac, valid_loss,train_loss] = nn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ac_valid = nn.accuracy(x_valid, y_valid)\n",
    "# ac_train = nn.accuracy(x_train, y_train)\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(i)\n",
    "# figure\n",
    "plt.plot(x, train_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch  0   4.343575062122489\n",
      "loss for epoch  1   0.1722105449354259\n",
      "loss for epoch  2   0.1471889534901068\n",
      "loss for epoch  3   0.13643469777021686\n",
      "loss for epoch  4   0.1364634457474806\n",
      "loss for epoch  5   0.132423139071859\n",
      "loss for epoch  6   0.13208689874179652\n",
      "loss for epoch  7   0.12717914305915753\n",
      "loss for epoch  8   0.12455246344901189\n",
      "loss for epoch  9   0.12203255458789872\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"loss for epoch \",i,\" \", train_loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\siddha~1\\docume~1\\courses\\monsoo~1\\ml2019~1\\hw3\\venv\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.9642356241234221\n",
      "loss  0.09940780557905077\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy \",nn.accuracy(X_test, y_test)/len(X_test))\n",
    "print(\"loss \",nn.closs(X_test, y_test)/len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = nn.weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 49 nearest neighbors...\n",
      "[t-SNE] Indexed 50 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 50 samples in 0.207s...\n",
      "[t-SNE] Computed conditional probabilities for sample 50 / 50\n",
      "[t-SNE] Mean sigma: 1.153572\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 48.074017\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.604862\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42, verbose=1)\n",
    "transformed_weights = tsne.fit_transform(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-fe765fbf25bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\siddha~1\\docume~1\\courses\\monsoo~1\\ml2019~1\\hw3\\venv\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\siddha~1\\docume~1\\courses\\monsoo~1\\ml2019~1\\hw3\\venv\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# only call close('all') if any to close\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# close triggers gc.collect, which can be slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.show(transformed_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with sklearn's MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['X', 'Y']>\n"
     ]
    }
   ],
   "source": [
    "filename = 'MNIST_Subset.h5'\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "    b_group_key = list(f.keys())[1]\n",
    "    # Get the data\n",
    "    data = list(f[a_group_key])\n",
    "    target = list(f[b_group_key])\n",
    "dat = []\n",
    "for i in range(len(data)):\n",
    "    l = []\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            l.append(data[i][j][k])\n",
    "    dat.append(np.asarray(l))\n",
    "dat = np.asarray(dat)\n",
    "target = np.asarray(target)\n",
    "f = []\n",
    "for i in range(len(target)):\n",
    "    if target[i] == 7:\n",
    "        f.append([1, 0])\n",
    "    else:\n",
    "        f.append([0, 1])\n",
    "tg = np.asarray(f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dat, tg, test_size=0.10, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, 50, 50), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 50, 50), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999082652967618\n",
      "0.9797297297297297\n",
      "0.9803646563814866\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(x_train,y_train))\n",
    "print(clf.score(x_valid, y_valid))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031684044027998873"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(clf.predict(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6642072383636679"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(clf.predict(x_valid),y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6297392610572785"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(clf.predict(X_test),y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
